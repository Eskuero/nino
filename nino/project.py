import os
import glob
import re
import subprocess
import copy
from .statics import statics

class project():
	def __init__(self, name, config):
		self.name = name
		pconfig = config["projects"].get(name, {})
		# Retrieve value for each property except for force because has different types
		for prop in statics.validprops:
			setattr(self, prop, pconfig.get(prop, config["projects"]["default"][prop]))
		# Detect the valid fetching method even when fetching is disabled because is needed on presentation
		self.fetcher = self.getfetchmethod()
		# FIXME: Do not load the entire dict into memory each time
		self.signinfo = config["keystores"]
		self.devices = config["devices"]
		# Forcing stores a list from cmdargs and a bool on project so check both
		self.force = name in config["force"] or pconfig.get("force", False)
		# Some properties are only generated by nino in the scope of retrying so avoid user interference
		self.signlist = pconfig.get("signlist", {}) if config["retry"] else {}
		self.deploylist = pconfig.get("deploylist", {}) if config["retry"] else {}
		# We need to store the output of every operation to a file
		self.logfile = open("log.txt", "w+")
		# Some properties are exclusive for the run
		self.changed, self.pull, self.built, self.failed, self.releases = False, 1, 1, {}, set()

	def presentation(self):
		# Retrieve and show basic information about the project
		if not self.fetcher:
			lastdate = "age unknown"
		else:
			log = subprocess.Popen(self.fetcher["lastdate"], stdout = subprocess.PIPE)
			lastdate = log.communicate()[0].decode('ascii').strip()
		print("------------------------------------------")
		print(self.name + " - last updated " + lastdate)

	def getfetchmethod(self):
		localdir = os.listdir()
		# Check every predefined method to see what's usable
		for method in statics.fetchmethods:
			if method in localdir:
				return statics.fetchmethods[method]
		# Returning after the loop ended means no method is feasible
		return False

	def fetch(self):
		print("SYNCING SOURCE CODE:")
		print("     FETCHING REMOTE ", end = "", flush = True)
		# If no program is usable, report and return
		if not self.fetcher:
			print("- \033[93mFETCH METHOD NOT FOUND\033[0m")
			return
		# Store the current local diff to restore it later
		if self.preserve:
			diff = subprocess.Popen(self.fetcher["diff"], stdout = subprocess.PIPE).communicate()[0];
		# Always clean local changes beforehand
		subprocess.call(self.fetcher["clean"], stdout = self.logfile, stderr = subprocess.STDOUT)
		# Get changes and save output/return code of the command for checks
		self.pull = subprocess.call(self.fetcher["pull"], stdout = self.logfile, stderr = subprocess.STDOUT)
		# Certain VCS (like mercurial) split syncing into pulling and updating so if a command is specified we need to execute it
		if self.fetcher["update"] and self.pull == 0:
			self.pull = subprocess.call(self.fetcher["update"], stdout = self.logfile, stderr = subprocess.STDOUT)
		# If something changed flag it for later checks	
		if self.pull == 0:
			# We need to pull back to the start of the file to be able to read anything
			self.logfile.seek(0)
			if self.fetcher["nonews"] not in self.logfile.read():
				print("- \033[92mUPDATED\033[0m")
				self.changed = True
			else:
				print("- \033[93mUNCHANGED\033[0m")
		else:
			self.failed.update({"sync": self.sync, "preserve": self.preserve, "build": self.build, "force": self.force, "tasks": self.tasks, "keystore": self.keystore, "keyalias": self.keyalias, "signlist": self.signlist, "deploylist": self.deploylist, "deploy": self.deploy})
			print("- \033[91mFAILED\033[0m")
		# If we are preserving we pipe and apply the previous relevant diff again
		if self.preserve and diff.decode() != "":
			print("     PRESERVING LOCAL CHANGES ", end = "", flush = True)
			apply = subprocess.Popen(self.fetcher["apply"], stdout = self.logfile, stderr = subprocess.STDOUT, stdin=subprocess.PIPE)
			apply.communicate(input=diff)
			if apply.returncode == 0:
				print("- \033[92mSUCCESSFUL\033[0m")
			else:
				print("- \033[91mFAILED\033[0m")
				self.failed.update({"build": self.build, "force": self.changed, "tasks": self.tasks, "keystore": self.keystore, "keyalias": self.keyalias, "signlist": self.signlist, "deploylist": self.deploylist, "deploy": self.deploy})
				self.build = False

	def package(self):
		print("BUILDING PACKAGE:")
		# Check if gradle wrapper exists before falling back to system-wide gradle
		if not os.path.isfile("gradlew" + statics.execsuffix):
			command = "gradle"
		else:
			command = statics.execprefix + "gradlew" + statics.execsuffix
		# User may provide an entrypoint that must be used as setup script before building
		if os.path.isfile("nino-entrypoint" + statics.execsuffix):
			print("     ENTRYPOINT SCRIPT ", end = "", flush = True)
			# Attempt to do the setup
			self.built = subprocess.call([statics.execprefix + "nino-entrypoint"], stdout = self.logfile, stderr = subprocess.STDOUT)
			if self.built != 0:
				print("- \033[91mFAILED\033[0m")
				self.failed.update({"build": self.build, "force": True, "tasks": self.tasks, "keystore": self.keystore, "keyalias": self.keyalias, "signlist": self.signlist, "deploylist": self.deploylist, "deploy": self.deploy})
				return
			else:
				print("- \033[92mSUCCESSFUL\033[0m")
		for task in self.tasks:
			print("     GRADLE TASK " + task + " ", end = "", flush = True)
			# Attempt the task, we also redirect stderr to stdout to effectively merge them.
			self.built = subprocess.call([command, "--no-daemon", self.tasks[task]["exec"]], stdout = self.logfile, stderr = subprocess.STDOUT)
			# If assembling fails we return to tell main
			if self.built != 0:
				print("- \033[91mFAILED\033[0m")
				# Save for retry only the failed tasks
				if "tasks" not in self.failed:
					self.failed["tasks"] = {}
				self.failed["tasks"].update({task: self.tasks[task]})
				self.failed.update({"build": self.build, "force": True, "tasks": self.failed["tasks"], "keystore": self.keystore, "keyalias": self.keyalias, "signlist": self.signlist, "deploylist": self.deploylist, "deploy": self.deploy})
			else:
				self.updatesignlist(task)
				print("- \033[92mSUCCESSFUL\033[0m")

	def updatesignlist(self, task):
		# Retrieve all present .apk inside projects folder
		apks = glob.glob("**/*.apk", recursive = True)
		# Filter out those that are not result of a Gradle task
		validroutes = re.compile(".*build(\\\\|\/)outputs(\\\\|\/)apk(\\\\|\/)")
		# Filter out those remaining from a previous failed task
		previous = copy.deepcopy(self.releases)
		self.releases = set(filter(validroutes.match, apks))
		# Discover which one are the outputs corresponding to the just finished task
		new = previous.symmetric_difference(self.releases)
		# Create a dictionary for each route containing apks
		outputs = {}
		apkroute = re.compile("[^\\\\|\/]*\.apk")
		for apk in new:
			# Determine the apk full route inside project
			route = re.sub(apkroute, "", apk)
			if route not in outputs:
				outputs[route] = {"apks": [], "splitnames": []}
			# Append each apk to the route index on the diccionary
			outputs[route]["apks"].append(apk)
		# Obtain the differences in the names of apks inside routes containing more than one output, because that means they must be treated as splitted apks
		for route in [route for route in outputs if len(outputs[route]["apks"]) > 1]:
			previous = outputs[route]["apks"][1].split("-")
			for apk in outputs[route]["apks"]:
				current = apk.split("-")
				# Get split names inside the list and join them back again
				differences = [item for item in current if item not in previous]
				outputs[route]["splitnames"].append("-".join(differences))
				previous = current
		# We are finally ready to prepare the signlist
		for route in outputs:
			for index, apk in enumerate(outputs[route]["apks"]):
				# Generate displayname from project name + task
				displayname = re.sub(validroutes, "", apk)
				# A path with a length of 3 means we have flavour names so we append them
				displayname = re.split("\\\\|\/", displayname)
				if len(displayname) == 3:
					displayname = self.name + "-" + task + "-" + displayname[0]
				else:
					displayname = self.name + "-" + task
				# Get keystore, keyalias and deploy targets from task if they exist, else fallback to project, which already fell back to defconfig
				keystore = self.tasks[task].get("keystore", self.keystore)
				keyalias = self.tasks[task].get("keyalias", self.keyalias)
				deploy = self.tasks[task].get("deploy", self.deploy)
				# Append split name if required (there's more than one apk in the route)
				if len(outputs[route]["apks"]) > 1:
					displayname = displayname + "-" + outputs[route]["splitnames"][index]
					# Override deploy configuration if specified
					if outputs[route]["splitnames"][index] in self.tasks[task].get("splits", []):
						deploy = self.tasks[task]["splits"][outputs[route]["splitnames"][index]].get("deploy", deploy)
				# Create a new entry with all the required data to continue the process
				self.signlist[apk] = {
					"displayname": displayname + ".apk",
					"keystore": keystore,
					"keyalias": keyalias,
					"deploy": deploy
				}


	def sign(self):
		print("SIGNING OUTPUTS:")
		# Store the list of failed to sign outpusts and devices to deploy later on a different dict
		failedsignlist = {}
		# Loop through the remaining apks (there may be different flavours)
		for apk in self.signlist:
			print("     " + self.signlist[apk]["displayname"] + " ", end = "", flush = True)
			# Verify whether is needed or not to sign, as some outputs may come out of building process already signed
			verify = subprocess.call(["apksigner" + statics.execsuffix, "verify", apk], stdout = self.logfile, stdin=subprocess.PIPE, stderr=subprocess.STDOUT)
			if verify == 1:
				# Sign the .apk with the provided key
				sign = subprocess.Popen(["apksigner" + statics.execsuffix, "sign", "--ks", self.signinfo[self.signlist[apk]["keystore"]]["path"], "--ks-key-alias", self.signinfo[self.signlist[apk]["keystore"]]["aliases"][self.signlist[apk]["keyalias"]]["name"],"--out", statics.workdir + "/NINO-RELEASES/" + self.signlist[apk]["displayname"], "--in", apk], stdout = self.logfile, stdin=subprocess.PIPE, stderr=subprocess.STDOUT)
				# Generate the input using the two passwords and feed it to the subprocess
				secrets = self.signinfo[self.signlist[apk]["keystore"]]["password"] + "\n" + self.signinfo[self.signlist[apk]["keystore"]]["aliases"][self.signlist[apk]["keyalias"]]["password"]
				sign.communicate(input=secrets.encode())
				if sign.returncode == 0:
					# If everything went fine add the new .apk to the list of releases
					self.updatedeploylist(self.signlist[apk]["displayname"], self.signlist[apk]["deploy"])
					os.remove(apk)
					print("- \033[92mSUCCESSFUL\033[0m")
				else:
					failedsignlist[apk] = self.signlist[apk]
					print("- \033[91mFAILED\033[0m")
			else:
				self.updatedeploylist(self.signlist[apk]["displayname"], self.signlist[apk]["deploy"])
				os.rename(apk, statics.workdir + "/NINO-RELEASES/" + self.signlist[apk]["displayname"])
				print("- \033[93mUNNEEDED\033[0m")
		# If we failed at least on one output we need to save it for the retry run
		if failedsignlist:
			self.failed.update({"keystore": self.keystore, "keyalias": self.keyalias, "signlist": failedsignlist, "deploylist": self.deploylist, "deploy": self.deploy})

	def updatedeploylist(self, apk, targets):
		devices = set()
		for roster in targets:
			devices = devices.union(set(self.devices.get(roster, {}).get("list", [])))
		self.deploylist[apk] = list(devices)

	def install(self):
		print("DEPLOYING OUTPUTS:")
		# Store the list of failed to deploy outputs and devices on a different dict
		faileddeploylist = {}
		for apk in self.deploylist:
			print("     " + apk, end = "", flush = True)
			# If no target is specified for the output we skip this iteration
			if not self.deploylist[apk]:
				print(" - \033[93mNO TARGETS\033[0m")
				continue
			else:
				print()
			faileddeploylist[apk] = []
			for target in self.deploylist[apk]:
				print("          TO DEVICE " + target + " ", end = "\r")
				try:
					# Make sure the device is online before proceeding, timeout after 15 secs of waiting
					print("          TO DEVICE " + target + " - \033[93mCONNECTING   \033[0m", end = "\r")
					subprocess.call(["adb", "-s", target, "wait-for-device"], timeout = 15, stdout = self.logfile, stderr = subprocess.STDOUT)
				# If the adb subprocess timed out we skip this device
				except subprocess.TimeoutExpired:
					faileddeploylist[apk].append(target)
					print("          TO DEVICE " + target + " - \033[91mNOT REACHABLE\033[0m")
					print("Not reachable", file = self.logfile, flush = True)
				else:
					print("          TO DEVICE " + target + " - \033[93mDEPLOYING    \033[0m", end = "\r")
					# We send the apk trying to override it on the system if neccessary
					send = subprocess.call(["adb", "-s" , target, "install", "-r", statics.workdir + "/NINO-RELEASES/" + apk], stdout = self.logfile, stderr=subprocess.STDOUT)
					if send == 0:
						print("          TO DEVICE " + target + " - \033[92mSUCCESSFUL   \033[0m")
					else:
						faileddeploylist[apk].append(target)
						print("          TO DEVICE " + target + " - \033[91mFAILED       \033[0m")
			if len(faileddeploylist[apk]) < 1:
				faileddeploylist.pop(apk)
		# We need to retry if at least one output wasn't delivered
		if faileddeploylist:
			self.failed.update({"deploylist": faileddeploylist, "deploy": self.deploy})
